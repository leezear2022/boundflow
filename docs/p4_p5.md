我先说结论：**你现在的 Phase 4 产出（Task pipeline + StoragePlan + LinearSpec(C) 对齐）是对的，而且已经把 Phase 5 真正要做的“Planner/全局优化”地基打牢了。**Phase 5 不应该急着上 BaB 全量，而是把 **“可扩展的 Global Planner + 最小 CROWN/CROWN-IBP + cache/reuse + TVM 端到端性能闭环”**做成一个可以持续迭代的系统骨架；BaB 作为 *Planner 的一种上层工作负载* 挂进来即可（α,β-CROWN 就是“bound propagation + BaB”的典型形态 ）。

下面按你要求：**从工程角度**，从 Phase 4 收尾写到 Phase 5（并把两者连接关系讲清楚），给你一份可直接让模型生成工程的路线图。

---

## Phase 4 现状校验：你的变更与“正确路线”是否一致

你列的三段变更（4A CNN+permute、4B.0 StoragePlan、4B.2 LinearSpec(C) 融合末层）总体与“系统化 verifier 编译框架”路线一致，尤其是：

* **C 矩阵不是 post-hoc 乘 logits interval**，而是应尽量**融合到最后线性层**，避免额外松弛——你已经按这个方向做了（这和 auto_LiRPA 把线性 spec 当作线性层来处理的思路一致，compute_bounds 也把 `C` 作为一等输入参数 ）。
* **StoragePlan 先钉 schema**是对的：后面任何“task 切分 / kernel fusion / TVM lowering / cache reuse / 多设备并行”都会反过来要求你能精确控制 buffer 生命周期。

**我唯一会“批评”的点**：Phase 4 现在还缺两个“收尾钉子”，否则 Phase 5 Planner 很容易返工。

---

## Phase 4 必须补齐的尾巴（建议定义成 4B.3 + 4C.0～4C.2）

### 4B.3 Layout/Transpose 作为可优化对象（不是做优化，是把 IR 说清楚）

**目标**：把“layout/permute 是 hint 还是语义 op”讲清楚，并把二者都能表达出来。

最小要求：

* `TensorType.layout`（或 `Value.layout_tag`）只表达**约定**（NCHW/NHWC/blocked），不表达具体 permute。
* `transpose/permute` 仍是**语义 op**（你已实现），但 Planner 可以把它标为 `movable`/`foldable`，为后续消除/下推留接口。
* 加一个 `layout_analysis_pass`：输出每个 value 的“可能 layout 集合/偏好”，先不做变换。

**DoD（完成标准）**：
给定含 permute 的 CNN：

1. 语义执行不变（对齐测试仍过）
2. Planner 能打印/导出 layout 报告（哪怕只用于 debug）

### 4C.0 TVMExecutor v0（先挑 1～2 个 op 做“可测的加速闭环”）

你/另一个模型的建议是对的：**不要急着把 orchestration 塞进 Relax VM**。先 Python driver 调 TVM 编译 kernel，建立“同一 BFTaskModule：Python vs TVM 输出一致”的可回归基线。

建议从这两个 kernel 开始（最容易验证、收益也直观）：

* `interval_linear`（包含你 4B.2 的 batched weight `[B,O,I]` 版本）
* `interval_conv2d`（先 NCHW，stride/pad 基础版）

**DoD**：

* `TVMExecutor.run_ibp(...)` 输出与 `PythonTaskExecutor` 误差在容忍范围（float32 下通常可做到 bitwise 近似；若用不同算子实现，设定 atol/rtol）
* 有 microbench：同一模型、同一 batch，TVMExecutor 比 Python 快（哪怕只快 1.5×，关键是闭环）

### 4C.1 TaskOp lowering “选择表”

Phase 5 Planner 要做“全局计划”，你 Phase 4 先把接口钉住：

* `TaskOp.lowering = {backend: "python"/"tvm", kernel_key, schedule_hint, layout_hint}`
  先 hardcode 一个 dict 都行。

---

## Phase 5 要做什么：把 “Planner” 做成系统的核心资产

先对齐概念：在 α,β-CROWN 体系里，**bound propagation 是主计算引擎**，BaB 只是上层不断“加约束/分裂节点”的驱动，它依赖你能高效重复算 bounds、复用 cache、批处理多个节点/多个 spec 。auto_LiRPA 的 `compute_bounds(...)` 里也明确暴露了很多“复用/缓存”接口（`reuse_ibp`, `reuse_alpha`, `cache_bounds` 等）——Phase 5 就是把这些“库层能力”升级为“编译系统能力”。

我建议把 Phase 5 拆成 **5A～5E**，每一段都能独立产出、可回归、可发版。

---

## Phase 5A：Global Planner v1（从“整图一个 task”到“多 task + 依赖图”）

**目标**：Planner 产出一个 `TaskGraph`（DAG），每个节点是 `BoundTask`，边是 buffer 依赖；Executor 按 DAG 调度。

最小切分策略（先别上 cost model）：

1. **forward region**：conv/linear + bias + relu 可以形成 1 个 region（IBP 里 lower/upper 的算子很固定）
2. **layout region**：permute 单独成 task（后续可消除/融合）
3. **spec region**：最后线性/LinearSpec 融合后的那一段单独 task（便于复用、便于多 spec 批处理）

**交付物**

* `boundflow/ir/task_graph.py`：TaskGraph、edges、topo sort
* `boundflow/planner/passes/partition.py`：region 切分
* `boundflow/runtime/scheduler.py`：按 topo 顺序跑（先串行）

**DoD**

* 现有测试全部通过
* 新增测试：同一 program，Planner v0（单 task）与 Planner v1（多 task）输出一致

---

## Phase 5B：Memory/Storage 升级成“liveness + reuse + alias”

你已经有 StoragePlan schema（非常关键）。Phase 5B 做两件事：

1. **liveness analysis**：每个 buffer 的 last_use、可释放点
2. **reuse policy**：同 shape/dtype 的 buffer 复用（greedy 就行），并允许 `inplace_ok`（比如 relu 的 interval 可尝试 inplace，但要小心上下界别名）

**交付物**

* `boundflow/planner/passes/liveness.py`
* `boundflow/planner/passes/buffer_reuse.py`
* `tests/test_phase5b_peak_memory_reduction.py`：比较 v0（一值一 buffer）与 v1（reuse）峰值 buffer 数/bytes

**DoD**

* 峰值内存下降（哪怕 20% 也是有效里程碑）
* 输出一致性测试通过

---

## Phase 5C：最小 CROWN / CROWN-IBP 闭环（先“能跑 + 对齐”，再谈紧）

auto_LiRPA 支持 IBP、Backward LiRPA（CROWN/DeepPoly）、以及混合策略（例如 IBP+Backward）。Phase 5C 的正确姿势是：

* **先做 CROWN-IBP**：中间层用 IBP 给出 interval（你已经有），最后层/输出用 backward 线性界收紧（最小实现先支持 linear + relu）。
* 把它作为一个新 `Domain`：`LinearDomainState`（存 A,b 或等价形式），并把它接到 TaskIR（第二层 BoundOp）上。

**交付物**

* `boundflow/domains/linear.py`：Linear bound state（最小）
* `boundflow/ir/bound.py`：BoundOp 真正进入主流程（不再占位）
* `boundflow/planner/crown_v0.py`：生成 backward task（从 output 往回）
* 对齐测试：对齐 auto_LiRPA `compute_bounds(method="backward"/"CROWN")` 或者 `IBP=True + backward` 的组合（按 auto_LiRPA 文档参数来选）

**DoD**

* 在 MLP + 小 CNN 上，CROWN(-IBP) 输出不劣于 IBP（至少更紧或相等）
* 对齐测试稳定

---

## Phase 5D：Cache/Reuse 机制（为 BaB 与训练“批处理”打底）

这一步非常“系统论文味”，也是未来你要加速的核心点：BaB 会重复算很多次 bounds；训练会反复对同一结构算 bounds。auto_LiRPA API 里明确提供了 `reuse_ibp`, `reuse_alpha`, `cache_bounds` 等机制，你的系统要把它升级为：

* **跨 task 的 cache key**：`(op_id, domain, spec_id, split_state, input_eps, …)`
* **cache scope**：一次 run 内 / 多次 run 间（训练 loop）
* **batching hook**：未来 BaB 的多个 node（split state 不同）可以组成 batch，一次 kernel 算多个

**交付物**

* `boundflow/runtime/cache.py`：BoundCache（LRU/分层 cache）
* `boundflow/runtime/batch_runner.py`：把多个 spec / 多个 split node 组成 batch（先对 spec 做 batch 就够了）
* `tests/test_phase5d_cache_hits.py`：同一输入重复 compute，cache hit 次数可观测

**DoD**

* cache hit 真实发生（日志/计数器）
* 性能回归：重复运行明显更快

---

## Phase 5E：TVM 扩展到 “Linear/CROWN 核心算子” + 性能评估基准

有了 5C 的 Linear bound，TVM 端最值钱的 kernel 往往是：

* `A @ W` / `A @ W_pos + A @ W_neg` 这类（各种形式的线性传播）
* 大量 reshape/transpose（如果你 4B.3 把 layout/permute 作为可优化对象，就能减少它）

**交付物**

* `boundflow/runtime/tvm_executor.py` 支持 linear-domain 的核心 kernel
* `benchmarks/`：固定模型集（MLP、MNIST CNN、你 RRAM 小网），输出：

  * wall time
  * kernel time（可选 NVTX）
  * peak memory（来自 StoragePlan 统计）

**DoD**

* TVM 路径比 Python 路径快（这是你后面写 ASPLOS 的硬证据）

---

## BaB 放在哪：Phase 6，而不是 Phase 5（但 Phase 5 要把“接口钉子”留好）

β-CROWN 的核心思想是把 split constraint 融入 bound propagation，使 BaB 更适合 GPU 并行。你 Phase 5 不需要实现完整 BaB，但要在 IR/Runtime 预留：

* `SplitState`（对 ReLU 的 active/inactive/ambiguous 标记）
* `ConstraintStore`（后续可以接 MIP/SMT/cuts；你之前提的“预留 deepoly/zonotope/mip/smt/qnn 接口”也在这里落点）

这也和你“预留其它鲁棒性框架接口”的目标一致。

---

## 你问“参考最近提交”这件事：我这边的限制

我尝试直接抓取 `github.com/leezear2022/boundflow` 的网页，但目前检索侧没拿到有效页面（很可能是仓库私有或抓取受限），所以**我没法可靠地逐条按 commit message 点评**。但你在对话里给的 Phase 4 变更摘要已经足够作为 Phase 5 规划输入；如果你想让我做“逐文件/逐提交”级别的 code review，最稳的是把 repo 打包成 zip（或导出关键目录）再发我。

---

## 把你的 4B/4C 计划与我的 Planner 设计综合成一句“最短主线”

**Phase 4 收尾（4B.3 + 4C.0～4C.2）**：把 layout/transpose 说清楚 + TVMExecutor 闭环跑通
→ **Phase 5A/5B**：Global Planner 产出 TaskGraph + 内存复用
→ **Phase 5C/5D**：最小 CROWN-IBP + cache/reuse（直接对标 auto_LiRPA 的复用接口 ）
→ **Phase 5E**：TVM 覆盖线性传播核 + 基准评测
→ **Phase 6**：BaB（β-CROWN 风格）作为上层 workload 接进来

如果你愿意，我也可以按你现在的目录结构，直接给出 **Phase 5 各模块的“文件清单 + 类/函数签名草案 + 单测命名”**，让你把它当成工程生成 prompt 的“唯一真相文档”。
